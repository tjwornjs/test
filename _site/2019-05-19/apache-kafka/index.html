<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Apache Kafka 논문정리</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" type="text/css">

  <!-- Font -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono" rel="stylesheet">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for 그저그런 공돌이" href="/feed.xml" />
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Apache Kafka 논문정리 | 그저그런 공돌이</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Apache Kafka 논문정리" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="아파치 카프카 논문정리" />
<meta property="og:description" content="아파치 카프카 논문정리" />
<link rel="canonical" href="http://localhost:4000/2019-05-19/apache-kafka/" />
<meta property="og:url" content="http://localhost:4000/2019-05-19/apache-kafka/" />
<meta property="og:site_name" content="그저그런 공돌이" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-19T21:28:29+09:00" />
<script type="application/ld+json">
{"description":"아파치 카프카 논문정리","headline":"Apache Kafka 논문정리","dateModified":"2019-05-19T21:28:29+09:00","datePublished":"2019-05-19T21:28:29+09:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2019-05-19/apache-kafka/"},"url":"http://localhost:4000/2019-05-19/apache-kafka/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->



  <!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>



</head>

<body>
  <div class="content-container">
    <header>
  <div class="header-small">
    <a href="http://localhost:4000">그저그런 공돌이</a>
  </div>
</header>
<div class="post">
  <div class="post-title">Apache Kafka 논문정리</div>
  <span class="post-date">
    <time>19 May 2019</time>
  </span>
  <div class="post-tag">
    <ul>
      
      <li>
        <a href="http://localhost:4000/tags#논문 정리">
          <span>논문 정리</span>
        </a>
      </li>
      
      
      <li>
        <a href="http://localhost:4000/tags#카프카">
          <span>카프카</span>
        </a>
      </li>
      
      
    </ul>
  </div>

  <h3 id="abstract">Abstract</h3>
<p>짧은 시간에 대량의 로그를 수집 및 전송할수 있는 분산 메시징 시스템 <a href="/assets/docs/kafka.pdf">논문 링크</a>  <br />
기존에 존재하던 log aggregator, messaging system의 아이디어를 통합하여 온라인 오프라인 메시지 소비가 가능고, yet practical design을 채택해 효율적이고 쉽게 확장가능한 시스템을 개발하였다.</p>

<h3 id="introduction">Introduction</h3>
<p>큰 규모의 인테넷 회사에서는 많은 양의 로그가 생성이 되고 이러한 로그는 보통 아래와 같은 정보를 포함한다.</p>
<ol>
  <li>사용자의 활동 : 좋아요, 클릭, 로그인</li>
  <li>메트릭 : 서비스 호출, cpu 사용량, 디스크 사용률</li>
</ol>

<p>전통적으로 로그데이터는 유저의 참여도, 시스템 활용도등을 분석하는 컴포넌트로 사용되어 왔으며, 최근에는 사이트(서비스)에서 직접 사용하는 데이터의 일부가 되었다.</p>
<ol>
  <li>검색 적합성</li>
  <li>추천 서비스</li>
  <li>광고 타겟팅 및 보고</li>
  <li>보안 프로그램 : 스팸, 데이터 스크래핑</li>
  <li>SNS의 사용자 업데이트 등</li>
</ol>

<p>이러한 로그 데이터를 사용하기에는 어려움이 많다.</p>
<ol>
  <li>데이터 용량
    <ul>
      <li>추천, 검색, 광고 서비스에서는 자용자의 클릭 뿐만 아니라 클릭되지 않은 각 페이지의 수십개 항목에 대해서도 데이터가 필요함</li>
    </ul>
  </li>
  <li>로그 데이터 수집
    <ul>
      <li>지금까지 로그 파일을 수집하는 방법은 주로 서버에서 물리적으로 스크래핑</li>
      <li>오프라인 수집용 플랫폼만 존재 : Scribe(facebook), Data Highway(yahoo), Flume(cloudera) 등 오프라인 전송만 지원</li>
    </ul>
  </li>
</ol>

<h3 id="related-work">Related Work</h3>
<p>기존의 메시징 시스템은 로그 프로세싱에 좋지 못하다.</p>
<ol>
  <li>로그 처리에 필요없는 다양한 기능들을 제공
    <ul>
      <li>실제로 로그처리에서 일부 로그가 유실되는건 큰 문제가 되지 않지만 기존 메시징 시스템은 100% 전송을 보장하기 때문에 시스템의 복잡성만 증가시킴</li>
    </ul>
  </li>
  <li>throughput을 고려하지 않고 설계됨
    <ul>
      <li>일부 시스템에는 배치 전송이 없다.</li>
    </ul>
  </li>
  <li>분산 시스템에 대한 고려 부족</li>
  <li>메세지가 즉각적으로 소비될 것을 전제로 하기때문에 메모리 크기가 매우 작고 그로 인해 메세지가 많이 쌓일 경우 성능이 하락한다.
최근 나온 Scribe, Data Highway, Flume등의 오픈소스가 등장했지만 Push 모델이었다. 이러한 문제점을 해결하기 위해 링크드인에서는 Pull 모델의 Kafka를 개발하였다.</li>
</ol>

<p>Pull 모델 장점</p>
<ol>
  <li>Consumer가 처리할수 있는 메세지만큼  소비함</li>
  <li>처리한 오프셋을 저장하기 때문에 에러 발생시 쉽게 재시작을 할수 있다.</li>
</ol>

<h3 id="kafka-architecture-and-design-principles">Kafka Architecture and Design Principles</h3>
<p>카프카 아키텍쳐
<img src="/assets/images/kafka/kafka architecture.png" alt="카프카 아키텍쳐" width="600" class="center-image" />
카프카 브로커는 여러 노드들로 구성되며 로드 밸런싱을 위해 토픽은 여러 파티션으로 나누어 지게 되며 각 브로커는 하나 또는 여러개의 파티션을 저장한다. 다수의 생성자가 메세지를 전달 다수의 소비자가 메세지를 소비 할수 있다.</p>
<ul>
  <li>토픽(topic) : 메세지의 타입, DB의 table로 생각하면 될듯</li>
  <li>파티션(partition) : 토픽의 데이터를 분산 저장하는 단위. 여러 파티션이 모여 하나의 토픽을 이룬다.</li>
  <li>프로듀서(producer) : 메세지를 브로커로 전송하는 프로그램(filebeat, apache server 등등)</li>
  <li>브로커(broker) : 카프카 서버, 프로듀서가 전송한 메세지를 저장하고 컨슈머에 메세지를 전송한다.</li>
  <li>컨슈머(consumer) : 브로커의 메세지를 소비하는 프로그램.</li>
</ul>

<h4 id="efficiency-on-a-single-partition">Efficiency on a Single Partition</h4>
<p>카프카를 효율적인 시스템으로 만들기 위해 아래와 같이 구현함</p>
<h5 id="simple-storage">Simple storage</h5>
<ul>
  <li>프로듀서가 메세지를 전송하면 브로커는 마지막 세그먼트 파일에 메세지를 추가해 저장한다.</li>
  <li>성능 하락을 막기 위해  설정된 갯수 만큼의 메세지가 들어오거나 일정 시간이 흐른 후 세그먼트 파일을 디스크로 저장한다.
    <ul>
      <li>메세지는 디스크에 저장된후 컨슈머에 노출됨</li>
    </ul>
  </li>
  <li>전통적인 메시징 시스템과는 다르게 카프카에 저장된 메세지는 명시적인 id가 없이 논리적 오프셋에 의해 처리된다.
    <ul>
      <li>메세지 id를 실제 메세지 위치에 매핑하는 인덱스 색인 구조를 유지 할 필요가 없다.</li>
      <li>id는 증가하지만 연속적이지는 않다.</li>
      <li>다음 메세지 id를 계산하기 위해 현재 메세지 크기를 저장해 둔다</li>
    </ul>
  </li>
  <li>컨슈머는 항상 특정 파티션의 메세지를 순차적으로 읽어간다.
    <ul>
      <li>브로커에 읽어올 오프셋 및 허용 바이트가 포함된 요청을 보낸다.</li>
      <li>오프셋 못록을 확인한 브로커가 적합한 세그먼트 파일을 찾아 해당 오프셋의 데이터를 전송함</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/images/kafka/kafka storage.png" alt="카프카 스토리지" width="600" class="center-image" /></p>

<h5 id="efficient-transfer">Efficient transfer</h5>
<p>카프카는 브로커는 읽어온 데이터를 개싱하지 않고 os의 페이지 캐시를 이용한다.</p>
<ul>
  <li>java heap, os cache에 이중으로 저장되는걸 막는다.</li>
  <li>os에 읽어온 데이터 캐싱되어 있기 때문에 브로커 서버가 재시작시 warm up 시간 단축.</li>
  <li>GC 오버헤드가 없다.
프로듀서, 컨슈머 모두 세그먼트 파일에 순차적으로 접근하며 보통 컨슈머가 프로듀서 보다 살짝 뒤쳐져 있기 때문에 os 캐싱(write through, read-ahead)가 매우 효과적으로 동작함</li>
</ul>

<p>카프카는 멀티 소비가 가능한 시스템이기 때문에 하나의 메세지가 여러번 소비 될때가 있다. 이러한 경우 일반적인 데이터 전송 방식은 아래와 같다.
<img src="/assets/images/kafka/kafka copy.gif" alt="zero-copy x" width="400" class="center-image" /></p>
<ol>
  <li>storage에서 읽어서 페이지 캐시에 저장</li>
  <li>페이지 캐시 데이터 application buffer에 복사</li>
  <li>다시 커널 버퍼로 복사</li>
  <li>커널 버퍼 데이터 소켓으로 전송</li>
</ol>

<p>매번 2, 3번의 데이터 복사를 하기 때문에 성능 하락이 생길수 있다. 카프카는 zero-copy 기법을 이용해 2,3번의 복사를 없애고 성능을 향상 시켰다.
<img src="/assets/images/kafka/kafka copy x.gif" alt="zero copy" width="400" class="center-image" /></p>

<h5 id="stateless-broker">Stateless broker</h5>
<p>카프카는 다른 메시징 시스템과는 다르게 카프카는 각 컨슈머가 데이터를 어디까지 읽어 갔는지 관리 하지 않는다.</p>
<ul>
  <li>브로커의 기능을 단순화 하여 오버헤드를 줄임</li>
</ul>

<p>따라서 이미 읽어간 데이터를 언제 지울지 결정하기 어렵다.</p>
<ul>
  <li>Time based SLA를 이용해 일정 기간이 지난 데이터를 삭제한다(기본 1주)
    <ul>
      <li>컨슈머는 실시간 또는 짧은 기간 이내 데이터 소비를 마친다. - 실상 1주일 전 데이터를 읽어갈 경우는 거의 없다.</li>
      <li>디스크 용량만 충분하다면 브로커에 저장된 데이터 크기에 따른 성능 저하가 미미하기 때문에 1주일치 데이터 저장도 가능함</li>
    </ul>
  </li>
</ul>

<p>이에 따른 이점은</p>
<ul>
  <li>컨슈머 실패시 지정된 오프셋부터 재시작 가능하다. pull 모델의 이점</li>
</ul>

<h4 id="distributed-coordination">Distributed Coordination</h4>
<p>각각의 프로듀서는 임의로 선택된 파티션 또는 파티셔닝 함수에 의해 결정된 파티션으로 메세지를 전달한다.  <br />
컨슈머 그룹</p>
<ul>
  <li>토픽을 소비하는 하나 이상의 컨슈머로 구성됨</li>
  <li>서로 다른 그룹은 각각 독립적으로 메세지를 소비하기 때문에 coordination이 필요 없다.
 <img src="/assets/images/kafka/consumer group.png" alt="consumer group" width="400" class="center-image" /></li>
</ul>

<p>파티션 : 토픽내 병철 처리의 가장 작은 단위</p>
<ul>
  <li>파티션 데이터는 하나의 컨슈머에 의해서만 소비됨</li>
  <li>하나의 파티션을 어러 컨슈머가 소비하면 이를 관리하기 위한 오버헤드가 발생한다.</li>
  <li>로드 밸런싱이 잘되도록 하기 위해선 파티션의 숫자가 컨슈머의 숫자의 n배수 여야 한다.</li>
</ul>

<p>주키퍼를 통해 고가용성(HA)를 지원한다. – 시스템 단순화</p>
<ul>
  <li>추가 문서에서 작성</li>
</ul>

<h4 id="delivery-guarantees">Delivery Guarantees</h4>
<p>카프카는 at-least-once 전송을 보장함</p>
<ul>
  <li>exactly-once는 two phase commit이 필요하며 카프카가 대상으로 하는 프로그램이 아니다.</li>
  <li>보통은 각 컨슈머에 1번만 전달이 되지만 컨슈머가 정상 종료되지 않으면 다른 컨슈머가 해당 컨슈머의 파티션 데이터를 소비하게 되고 중복 처리할 수 있다.</li>
  <li>만약 메세지 중복이 중요한 이슈가 되면 컨슈머에서 자체적인 중복 방지 로직을 추가해야 한다.</li>
</ul>

<p>파티션에 대해서만 순서를 보장함. 서로 다른 파티션에서 데이터를 읽어올때는 순서를 보장할수 없다. <br />
로그가 잘못쓰여진 경우를 대비해 각 메세지에 CRC 저장 <br />
브로커가 죽으면 브로커에 저장된 메세지는 사용 불가</p>
<ul>
  <li>이제는 <strong>replication</strong>이 있기 때문에  문제 없다. 초기에는 복제가 없었던 듯</li>
</ul>

<h4 id="kafka-usage-at-linkedin">Kafka Usage at LinkedIn</h4>
<p>딱히 특별한건 없고 직렬화를 위해 스키마를 지원하는 Avro를 선택했다.  <a href="https://docs.confluent.io/current/schema-registry/index.html">schema-registry</a>를 이용해 Avro에 저장된  id에 해당하는 스키마를 매핑했다고 한다. schema registry는 다른 포스팅에서 다룰 예정</p>

<h4 id="experimental-results">Experimental Results</h4>
<p>R/W의 성능이 active mq, rabbit mq에 비해 월등히 좋은 결과를 보여준다. 이미 2개의 mq는 많이 사용하지 않고 오래전 결과이기 때문에 따로 정리할 필요는 없을 듯. 성능이 빠른 이유는 위에 설명한 내용과 비슷하다.</p>


  <!-- Disqus -->
  

</div>


    <!-- Documents about icons are here: http://fontawesome.io/icons/ -->
<div class="footer">
  <hr />
  <div class="footer-link">
    
	
	
	
	

    

    
    <a href="https://github.com/tjwornjs"><i class="fa fa-github" aria-hidden="true"></i></a>
    
	
	
	
	

    
	
	
	
	
	
	
	
	

    

    

    
    <a href="mailto:tjwornjs@gmail.com"><i class="fa fa-envelope" aria-hidden="true"></i></a>
    

  </div>
  © 2019 tjwornjs. All rights reserved.
</div>

  </div>
</body>
</html>
