---
title: Apache Kafka 논문정리
layout: post
description: 아파치 카프카 논문정리
date: '2019-05-19 21:28:29'
tags:
- 논문 정리
- 카프카
comments: true
---

### Abstract
짧은 시간에 대량의 로그를 수집 및 전송할수 있는 분산 메시징 시스템 [논문 링크]({{ "/assets/docs/kafka.pdf" }})    
기존에 존재하던 log aggregator, messaging system의 아이디어를 통합하여 온라인 오프라인 메시지 소비가 가능고, yet practical design을 채택해 효율적이고 쉽게 확장가능한 시스템을 개발하였다.

### Introduction
큰 규모의 인테넷 회사에서는 많은 양의 로그가 생성이 되고 이러한 로그는 보통 아래와 같은 정보를 포함한다.
1. 사용자의 활동 : 좋아요, 클릭, 로그인
1. 메트릭 : 서비스 호출, cpu 사용량, 디스크 사용률   


전통적으로 로그데이터는 유저의 참여도, 시스템 활용도등을 분석하는 컴포넌트로 사용되어 왔으며, 최근에는 사이트(서비스)에서 직접 사용하는 데이터의 일부가 되었다.
1. 검색 적합성
1. 추천 서비스
1. 광고 타겟팅 및 보고
1. 보안 프로그램 : 스팸, 데이터 스크래핑
1. SNS의 사용자 업데이트 등

이러한 로그 데이터를 사용하기에는 어려움이 많다.
1. 데이터 용량
	* 추천, 검색, 광고 서비스에서는 자용자의 클릭 뿐만 아니라 클릭되지 않은 각 페이지의 수십개 항목에 대해서도 데이터가 필요함
1. 로그 데이터 수집
  * 지금까지 로그 파일을 수집하는 방법은 주로 서버에서 물리적으로 스크래핑
  * 오프라인 수집용 플랫폼만 존재 : Scribe(facebook), Data Highway(yahoo), Flume(cloudera) 등 오프라인 전송만 지원


### Related Work
기존의 메시징 시스템은 로그 프로세싱에 좋지 못하다.
1. 로그 처리에 필요없는 다양한 기능들을 제공
  * 실제로 로그처리에서 일부 로그가 유실되는건 큰 문제가 되지 않지만 기존 메시징 시스템은 100% 전송을 보장하기 때문에 시스템의 복잡성만 증가시킴
1. throughput을 고려하지 않고 설계됨 
  * 일부 시스템에는 배치 전송이 없다.
1.  분산 시스템에 대한 고려 부족
1. 메세지가 즉각적으로 소비될 것을 전제로 하기때문에 메모리 크기가 매우 작고 그로 인해 메세지가 많이 쌓일 경우 성능이 하락한다.
최근 나온 Scribe, Data Highway, Flume등의 오픈소스가 등장했지만 Push 모델이었다. 이러한 문제점을 해결하기 위해 링크드인에서는 Pull 모델의 Kafka를 개발하였다.

Pull 모델 장점
1. Consumer가 처리할수 있는 메세지만큼  소비함
1. 처리한 오프셋을 저장하기 때문에 에러 발생시 쉽게 재시작을 할수 있다.

### Kafka Architecture and Design Principles
카프카 아키텍쳐
<img src="/assets/images/kafka/kafka architecture.png" alt="카프카 아키텍쳐" width="600">{: .center-image}
카프카 브로커는 여러 노드들로 구성되며 로드 밸런싱을 위해 토픽은 여러 파티션으로 나누어 지게 되며 각 브로커는 하나 또는 여러개의 파티션을 저장한다. 다수의 생성자가 메세지를 전달 다수의 소비자가 메세지를 소비 할수 있다.
* 토픽(topic) : 메세지의 타입, DB의 table로 생각하면 될듯
* 파티션(partition) : 토픽의 데이터를 분산 저장하는 단위. 여러 파티션이 모여 하나의 토픽을 이룬다.
* 프로듀서(producer) : 메세지를 브로커로 전송하는 프로그램(filebeat, apache server 등등)
* 브로커(broker) : 카프카 서버, 프로듀서가 전송한 메세지를 저장하고 컨슈머에 메세지를 전송한다.
* 컨슈머(consumer) : 브로커의 메세지를 소비하는 프로그램.

### Efficiency on a Single Partition
카프카를 효율적인 시스템으로 만들기 위해 아래와 같이 구현함
#### Simple storage 
* 프로듀서가 메세지를 전송하면 브로커는 마지막 세그먼트 파일에 메세지를 추가해 저장한다. 
* 성능 하락을 막기 위해  설정된 갯수 만큼의 메세지가 들어오거나 일정 시간이 흐른 후 세그먼트 파일을 디스크로 저장한다.
	* 메세지는 디스크에 저장된후 컨슈머에 노출됨
* 전통적인 메시징 시스템과는 다르게 카프카에 저장된 메세지는 명시적인 id가 없이 논리적 오프셋에 의해 처리된다.
	* 메세지 id를 실제 메세지 위치에 매핑하는 인덱스 색인 구조를 유지 할 필요가 없다.
	* id는 증가하지만 연속적이지는 않다.
	* 다음 메세지 id를 계산하기 위해 현재 메세지 크기를 저장해 둔다
* 컨슈머는 항상 특정 파티션의 메세지를 순차적으로 읽어간다.
	* 브로커에 읽어올 오프셋 및 허용 바이트가 포함된 요청을 보낸다.
	* 오프셋 못록을 확인한 브로커가 적합한 세그먼트 파일을 찾아 해당 오프셋의 데이터를 전송함

<img src="/assets/images/kafka/kafka storage.png" alt="카프카 스토리지" width="600">{: .center-image}

#### Efficient transfer
카프카는 브로커는 읽어온 데이터를 개싱하지 않고 os의 페이지 캐시를 이용한다.
* java heap, os cache에 이중으로 저장되는걸 막는다.
* os에 읽어온 데이터 캐싱되어 있기 때문에 브로커 서버가 재시작시 warm up 시간 단축.
* GC 오버헤드가 없다.
프로듀서, 컨슈머 모두 세그먼트 파일에 순차적으로 접근하며 보통 컨슈머가 프로듀서 보다 살짝 뒤쳐져 있기 때문에 os 캐싱(write through, read-ahead)가 매우 효과적으로 동작함

카프카는 멀티 소비가 가능한 시스템이기 때문에 하나의 메세지가 여러번 소비 될때가 있다. 이러한 경우 일반적인 데이터 전송 방식은 아래와 같다.
<img src="/assets/images/kafka/kafka copy.gif" alt="zero-copy x" width="400">{: .center-image}
1. storage에서 읽어서 페이지 캐시에 저장
1. 페이지 캐시 데이터 application buffer에 복사
1. 다시 커널 버퍼로 복사
1. 커널 버퍼 데이터 소켓으로 전송

매번 2, 3번의 데이터 복사를 하기 때문에 성능 하락이 생길수 있다. 카프카는 zero-copy 기법을 이용해 2,3번의 복사를 없애고 성능을 향상 시켰다.
<img src="/assets/images/kafka/kafka copy x.gif" alt="zero copy" width="400">{: .center-image}